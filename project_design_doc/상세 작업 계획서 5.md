---
root_main: "[[프로젝트/프로젝트_main|프로젝트_main]]"
deps: 0
title: 상세 작업 계획서 5
Project: 
Domain: 
Object: 
Scope: 
Asset: 
Source:
Maturity (%): 
entity_type: 
created: 2025-06-26
modified: 2025-06-26 14:01
folder_main: "[[프로젝트/프로젝트_main|프로젝트_main]]"
related_files:
---
### **Part 6: 테스팅 전략 상세 설계 (Testing Strategy)**

코드의 신뢰성을 확보하고, 변경에 따른 부작용(Side Effect)을 최소화하기 위해 체계적인 테스트 전략을 수립한다. pytest 프레임워크를 표준으로 사용한다.

#### **6.1. 단위 테스트 (Unit Testing)**

* **목표**: 각 컴포넌트(src/components/)가 독립적으로 정확하게 동작하는지 검증한다. 외부 의존성(API, 파일 시스템, DB)은 모의 객체(Mock Object)로 대체하여 테스트를 순수하게 유지한다.  
* **테스트 파일 위치**: tests/ 디렉토리 하위에 test\_\*.py 형식으로 생성한다.  
* **핵심 테스트 케이스 설계**:  
  * **tests/test\_data\_loader.py**:  
    * **test\_load\_and\_preprocess\_movielens**:  
      * 가짜 movies.csv, ratings.csv 파일을 tmp\_path (pytest fixture)에 생성한다.  
      * DataLoader 실행 후, 전처리된 Parquet 파일이 올바르게 생성되는지 확인한다.  
      * 생성된 DataFrame의 스키마(컬럼명), 데이터 타입, release\_year 추출 및 genres 분리 결과가 예상과 일치하는지 assert로 검증한다.  
  * **tests/test\_persona\_generator.py**:  
    * **test\_generate\_dummy\_watch\_history**:  
      * 미리 정의된 작은 MovieLens DataFrame과 페르소나 프로필을 사용한다.  
      * 생성된 더미 데이터의 레코드 개수가 요청한 num\_records와 일치하는지 확인한다.  
      * 페르소나의 선호 장르 영화들이 실제로 더 높은 평균 평점을 받았는지 통계적으로 검증한다.  
  * **tests/test\_content\_labeler.py**:  
    * **test\_generate\_labels\_success**:  
      * google.generativeai.GenerativeModel 객체를 unittest.mock.patch를 사용하여 모킹(mocking)한다.  
      * 모의 API가 예상된 JSON 형식의 응답을 반환하도록 설정한다.  
      * ContentLabeler가 이 응답을 성공적으로 파싱하여 파이썬 리스트를 반환하는지 검증한다.  
    * **test\_generate\_labels\_api\_failure**:  
      * 모의 API가 예외(Exception)를 발생시키도록 설정한다.  
      * ContentLabeler가 설정된 max\_retries 횟수만큼 재시도하는지 확인한다 (mock\_api.call\_count).  
      * 최종적으로 빈 리스트(\[\])를 반환하는지 검증한다.

#### **6.2. 통합 테스트 (Integration Testing)**

* **목표**: 여러 컴포넌트가 결합되었을 때, 특히 RecommendationEngine 내에서 데이터 흐름과 상호작용이 올바르게 이루어지는지 검증한다.  
* **tests/test\_recommendation\_engine.py**:  
  * **test\_generate\_recommendations\_pipeline**:  
    * **준비 (Setup)**:  
      * pytest의 fixture를 사용하여 테스트 실행 전에 필요한 모든 것을 준비한다.  
      * DataLoader는 실제 소규모 테스트 데이터셋을 로드하게 한다.  
      * RatingPredictor, ContentLabeler, ScheduleCrawler의 메서드들은 모두 모킹한다. 이 모의 메서드들은 실제 객체 대신 미리 정의된 예측 가능한 결과(e.g., 고정된 예상 평점 딕셔너리, 고정된 라벨 리스트)를 반환하도록 설정한다.  
    * **실행 (Execution)**:  
      * 모킹된 컴포넌트들로 초기화된 RecommendationEngine 인스턴스를 생성한다.  
      * engine.generate\_recommendations\_for\_persona()를 호출한다.  
    * **검증 (Assertion)**:  
      * 반환된 최종 결과 객체의 전체적인 구조가 Pydantic 스키마(RecommendationResult)와 일치하는지 검증한다.  
      * 각 컴포넌트의 모의 메서드가 정확히 1번씩 호출되었는지 확인한다 (mock.assert\_called\_once()).  
      * 최종 추천 리스트(recommendations)가 유사도 점수(similarity\_score) 기준으로 내림차순 정렬되었는지 확인한다.

### **Part 7: 캐싱 및 성능 최적화 전략**

사용자 경험과 운영 비용에 직결되는 시스템의 응답 속도 및 효율성을 개선하기 위한 전략을 수립한다.

#### **7.1. 데이터 캐싱 전략 (Data Caching Strategy)**

* **목표**: 반복적이고 비용이 많이 드는 작업(API 호출, 파일 I/O)의 결과를 저장하고 재사용하여 응답 시간을 단축하고 비용을 절감한다.  
* **1\. LLM 라벨 캐싱**:  
  * **문제**: 동일한 영화나 프로그램에 대해 추천을 생성할 때마다 LLM API를 호출하는 것은 매우 비효율적이고 비용이 많이 든다.  
  * **해결책**: Key-Value 형태의 영속적인 캐시를 구현한다.  
  * **구현 명세**:  
    * src/components/content\_labeler.py 내부에 캐싱 로직을 추가한다.  
    * **캐시 저장소**: SQLite 데이터베이스를 data/cache/llm\_labels.db 경로에 생성한다. 테이블 스키마는 (content\_hash TEXT PRIMARY KEY, labels\_json TEXT)로 구성한다.  
    * **캐시 키 생성**: hashlib.sha256((title \+ overview).encode()).hexdigest() 와 같이 콘텐츠 제목과 줄거리를 조합한 문자열의 해시값을 고유 키로 사용한다.  
    * **generate\_labels 메서드 수정**:  
      1. 메서드 시작 시, 입력된 title과 overview로 캐시 키를 생성한다.  
      2. DB에서 해당 키를 조회한다.  
      3. **캐시 히트(Cache Hit)**: 데이터가 존재하면, DB에서 labels\_json을 읽어와 JSON 파싱 후 즉시 반환한다. (API 호출 안 함)  
      4. **캐시 미스(Cache Miss)**: 데이터가 없으면, 기존 로직대로 LLM API를 호출하여 라벨을 생성한다.  
      5. 생성된 라벨 리스트를 JSON 문자열로 변환하여 DB에 (캐시 키, JSON 문자열) 쌍으로 저장한 후, 결과를 반환한다.  
* **2\. IPTV 편성표 캐싱**:  
  * **문제**: 여러 사용자가 같은 날짜의 편성표를 요청할 때마다 웹 크롤링을 반복하는 것은 비효율적이다.  
  * **해결책**: 날짜별로 편성표 파일 캐시를 구현한다.  
  * **구현 명세**:  
    * src/components/schedule\_crawler.py의 fetch\_schedule\_for\_date 메서드를 수정한다.  
    * **로직**:  
      1. target\_date를 기반으로 캐시 파일 경로를 결정한다 (e.g., data/processed/tv\_schedule\_{target\_date}.json).  
      2. 해당 경로에 파일이 존재하는지, 그리고 생성된 지 일정 시간(e.g., 6시간)이 지나지 않았는지 확인한다.  
      3. **캐시 히트**: 유효한 캐시 파일이 존재하면, 크롤링을 수행하지 않고 해당 파일을 읽어 즉시 반환한다.  
      4. **캐시 미스**: 파일이 없거나 너무 오래되었으면, 실제 웹 크롤링을 수행하고, 결과를 파일로 저장한 뒤 반환한다.

#### **7.2. 계산 및 로딩 최적화 (Computation & Loading Optimization)**

* **1\. Streamlit 애플리케이션 캐싱**:  
  * **(기존 설계 강화)** src/app.py에서 무거운 객체 로딩 시 Streamlit의 캐싱 데코레이터를 적극적으로 활용한다.  
  * **@st.cache\_resource**: 반환 값이 직렬화될 수 없는 복잡한 객체(e.g., RecommendationEngine 인스턴스, 학습된 모델 객체)를 로드하는 함수에 사용한다.  
  * **@st.cache\_data**: 순수한 계산 결과나 데이터프레임 등 직렬화 가능한 데이터를 반환하는 함수(e.g., 전처리된 데이터 로딩)에 사용한다.  
* **2\. 배치 처리 (Batch Processing)**:  
  * **RatingPredictor.predict\_ratings**: 현재 설계는 여러 영화에 대한 평점을 한번에 예측하도록 되어 있으므로 배치 처리의 이점을 이미 활용하고 있다.  
  * **ContentLabeler 및 임베딩**: 만약 여러 콘텐츠를 동시에 라벨링하거나 임베딩해야 할 경우, 개별적으로 처리하지 않고 리스트로 묶어 처리한다.  
    * **임베딩 최적화**: sentence\_transformers의 encode 메서드는 문자열 리스트를 입력받아 내부적으로 배치 처리를 수행하므로, 여러 문장을 한번에 인코딩하는 것이 훨씬 효율적이다. RecommendationEngine에서 사용자 취향 라벨과 프로그램 라벨을 모아서 한번에 임베딩하도록 로직을 구성한다.  
* **3\. 비동기 처리 (Asynchronous Processing \- 심화 과제)**:  
  * **문제**: 여러 콘텐츠에 대한 LLM 라벨링은 I/O Bound 작업(네트워크 통신 대기)이므로, 순차적으로 실행하면 전체 대기 시간이 길어진다.  
  * **해결책**: asyncio와 aiohttp/httpx를 사용하여 API 호출을 병렬로 실행한다.  
  * **구현 방향 (선택적)**:  
    * ContentLabeler 내에 async\_generate\_labels 메서드를 추가한다.  
    * 여러 콘텐츠에 대한 라벨링 요청이 들어오면, asyncio.gather를 사용하여 모든 API 요청을 동시에 보내고 응답을 기다린다.  
    * RecommendationEngine은 이 비동기 메서드를 asyncio.run으로 호출하여 여러 프로그램의 라벨링을 동시에 수행할 수 있다. 이는 특히 편성표 전체를 처음 라벨링할 때 응답 시간을 획기적으로 단축시킬 수 있다.

**(다음 파트에서 계속됩니다...)**